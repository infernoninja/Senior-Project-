{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "#Main Library (Actual Neural Network Part)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "import neural_structured_learning as nsl\n",
    "\n",
    "# #Helper Libraries (in order to interpret and view the data)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Prints if a GPU is detected by the TensorFlow system\n",
    "print(len(tf.config.list_physical_devices('GPU')) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the MNIST dataset from tensorflow\n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[0].shape)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #validating the data (making sure this is the data I want)\n",
    "# fig, ax = plt.subplots(2,5, figsize = (5,5))\n",
    "# ax = ax.flatten()\n",
    "# for i in range(10):\n",
    "#     im_idx = np.argwhere(Y_train == i)[0][0]\n",
    "#     plottable_image = X_train[im_idx]\n",
    "#     ax[i].imshow(plottable_image, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model - Sequential \n",
    "model = models.Sequential()\n",
    "#first conv. layer and pooling layer\n",
    "model.add(layers.Conv2D(8, (2, 2), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#second conv. layer and pooling layer\n",
    "model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#last conv. layer\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#last conv. layer\n",
    "model.add(layers.Conv2D(64, (2, 2), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 8)         104       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 16)        528       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          2080      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 64)          8256      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,968\n",
      "Trainable params: 10,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#checking the output shape of the last conv. layer, so I can set the last Dense layer correctly\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening layer will create vectors in order for the neural netowrk to actually make predictions\n",
    "model.add(layers.Flatten())\n",
    "#adding the last dense layer to allow the neural network to classify the images\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "#classification layer\n",
    "model.add(layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 8)         104       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 16)        528       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          2080      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 64)          8256      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,066\n",
      "Trainable params: 28,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n",
    "adv_model = nsl.keras.AdversarialRegularization(model, adv_config = adv_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiler which configures the model\n",
    "adv_model.compile(optimizer='adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x26509f54ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Cannot perturb non-Tensor input: dict_keys(['label'])\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x26509f54ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x26509f54ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5000/5000 [==============================] - 108s 16ms/step - loss: 1.8897 - sparse_categorical_crossentropy: 1.5577 - sparse_categorical_accuracy: 0.4301 - scaled_adversarial_loss: 0.3320\n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.5683 - sparse_categorical_crossentropy: 1.2809 - sparse_categorical_accuracy: 0.5382 - scaled_adversarial_loss: 0.2874\n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4407 - sparse_categorical_crossentropy: 1.1701 - sparse_categorical_accuracy: 0.5804 - scaled_adversarial_loss: 0.2705\n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 73s 15ms/step - loss: 1.3575 - sparse_categorical_crossentropy: 1.0976 - sparse_categorical_accuracy: 0.6078 - scaled_adversarial_loss: 0.2599\n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 1.2951 - sparse_categorical_crossentropy: 1.0432 - sparse_categorical_accuracy: 0.6261 - scaled_adversarial_loss: 0.2519\n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 1.2434 - sparse_categorical_crossentropy: 0.9979 - sparse_categorical_accuracy: 0.6451 - scaled_adversarial_loss: 0.2455\n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 1.2008 - sparse_categorical_crossentropy: 0.9606 - sparse_categorical_accuracy: 0.6579 - scaled_adversarial_loss: 0.2402\n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 1.1595 - sparse_categorical_crossentropy: 0.9249 - sparse_categorical_accuracy: 0.6717 - scaled_adversarial_loss: 0.2346\n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 1.1373 - sparse_categorical_crossentropy: 0.9050 - sparse_categorical_accuracy: 0.6790 - scaled_adversarial_loss: 0.2323\n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 1.1024 - sparse_categorical_crossentropy: 0.8749 - sparse_categorical_accuracy: 0.6906 - scaled_adversarial_loss: 0.2275\n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.0819 - sparse_categorical_crossentropy: 0.8566 - sparse_categorical_accuracy: 0.6944 - scaled_adversarial_loss: 0.2253\n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.0619 - sparse_categorical_crossentropy: 0.8389 - sparse_categorical_accuracy: 0.7024 - scaled_adversarial_loss: 0.2230\n",
      "Epoch 13/20\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 1.0433 - sparse_categorical_crossentropy: 0.8226 - sparse_categorical_accuracy: 0.7085 - scaled_adversarial_loss: 0.2207\n",
      "Epoch 14/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 1.0268 - sparse_categorical_crossentropy: 0.8077 - sparse_categorical_accuracy: 0.7137 - scaled_adversarial_loss: 0.2190\n",
      "Epoch 15/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 1.0106 - sparse_categorical_crossentropy: 0.7937 - sparse_categorical_accuracy: 0.7163 - scaled_adversarial_loss: 0.2169\n",
      "Epoch 16/20\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.9972 - sparse_categorical_crossentropy: 0.7818 - sparse_categorical_accuracy: 0.7210 - scaled_adversarial_loss: 0.2154\n",
      "Epoch 17/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.9830 - sparse_categorical_crossentropy: 0.7690 - sparse_categorical_accuracy: 0.7272 - scaled_adversarial_loss: 0.2139\n",
      "Epoch 18/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.9745 - sparse_categorical_crossentropy: 0.7612 - sparse_categorical_accuracy: 0.7294 - scaled_adversarial_loss: 0.2133\n",
      "Epoch 19/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.9584 - sparse_categorical_crossentropy: 0.7474 - sparse_categorical_accuracy: 0.7350 - scaled_adversarial_loss: 0.2110\n",
      "Epoch 20/20\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.9482 - sparse_categorical_crossentropy: 0.7380 - sparse_categorical_accuracy: 0.7371 - scaled_adversarial_loss: 0.2102\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "history = adv_model.fit({'feature': X_train, 'label': Y_train}, batch_size = 10, epochs = 20, verbose = 1,\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 15ms/step - loss: 1.2749 - sparse_categorical_crossentropy: 1.0027 - sparse_categorical_accuracy: 0.6622 - scaled_adversarial_loss: 0.2721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2748643159866333,\n",
       " 1.0027482509613037,\n",
       " 0.6621999740600586,\n",
       " 0.2721160650253296]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model.evaluate({'feature': X_test, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model.save('complete_saved_adv_cifar10_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "base_model = tf.keras.models.load_model('complete_saved_cifar10_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the adversarial attack for adversarial training\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def create_adv(input_image, input_label, model_type = \"adv_model\"):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    if(model_type == \"model\"):\n",
    "      prediction = base_model(input_image)\n",
    "    else:\n",
    "      prediction = model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad\n",
    "\n",
    "def fgsm(input_image, input_label, eps=0.25, model_type = \"adv_model\"):\n",
    "  perturbation = create_adv(input_image, input_label, model_type)\n",
    "  adv_image = input_image + perturbation * eps\n",
    "  adv_image = tf.clip_by_value(adv_image, 0, 1)\n",
    "\n",
    "  return adv_image\n",
    "\n",
    "def pgd(input_image, input_label, num_steps=100, eps=0.25, alpha=0.01, model_type = \"adv_model\"):\n",
    "  adv_image = input_image\n",
    "  for i in range(num_steps):\n",
    "    adv_image = fgsm(adv_image, input_label, alpha, model_type)\n",
    "    perturbation = adv_image - input_image\n",
    "    perturbation = tf.clip_by_value(perturbation, -eps, eps)\n",
    "    adv_image = input_image + perturbation\n",
    "  \n",
    "  return adv_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 17ms/step - loss: 8.5975 - sparse_categorical_crossentropy: 7.0372 - sparse_categorical_accuracy: 0.0664 - scaled_adversarial_loss: 1.5603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.597528457641602, 7.037239074707031, 0.06639999896287918, 1.5602933168411255]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_x = fgsm(tf.convert_to_tensor(X_test), Y_test)\n",
    "adv_model.evaluate({'feature': adv_x, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
