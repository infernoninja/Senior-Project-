{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "#Main Library (Actual Neural Network Part)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "import neural_structured_learning as nsl\n",
    "import torch\n",
    "from autoattack import utils_tf2\n",
    "from autoattack import AutoAttack\n",
    "\n",
    "# #Helper Libraries (in order to interpret and view the data)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('complete_saved_adv_mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 32)          4640      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,850\n",
      "Trainable params: 14,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.models.load_model('complete_saved_mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Prints if a GPU is detected by the TensorFlow system\n",
    "print(len(tf.config.list_physical_devices('GPU')) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the MNIST dataset from tensorflow\n",
    "from tensorflow.keras.datasets import mnist \n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data from 0 to 1 as float (decimal) numbers\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 4ms/step - loss: 0.0581 - accuracy: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05805297940969467, 0.9876999855041504]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#premiliminary testing (accuracy of benign images)\n",
    "model.evaluate(x = X_test, y = Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_config = nsl.configs.make_adv_reg_config(multiplier = 0.2, adv_step_size = 0.05)\n",
    "adv_model = nsl.keras.AdversarialRegularization(model, adv_config = adv_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiler which configures the model\n",
    "adv_model.compile(optimizer='adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aarush\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1ebd6b14ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Cannot perturb non-Tensor input: dict_keys(['label'])\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1ebd6b14ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1ebd6b14ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 10s 7ms/step - loss: 0.0736 - sparse_categorical_crossentropy: 0.0580 - sparse_categorical_accuracy: 0.9877 - scaled_adversarial_loss: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07364562153816223,\n",
       " 0.05796034634113312,\n",
       " 0.9876999855041504,\n",
       " 0.015685245394706726]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model.evaluate({'feature': X_test, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the adversarial attack for adversarial training\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def create_adv(input_image, input_label, model_type = \"adv_model\"):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    if(model_type == \"model\"):\n",
    "      prediction = base_model(input_image)\n",
    "    else:\n",
    "      prediction = model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad\n",
    "\n",
    "def fgsm(input_image, input_label, eps=0.25, model_type = \"adv_model\"):\n",
    "  perturbation = create_adv(input_image, input_label, model_type)\n",
    "  adv_image = input_image + perturbation * eps\n",
    "  adv_image = tf.clip_by_value(adv_image, 0, 1)\n",
    "\n",
    "  return adv_image\n",
    "\n",
    "def pgd(input_image, input_label, num_steps=100, eps=0.25, alpha=0.01, model_type = \"adv_model\"):\n",
    "  adv_image = input_image\n",
    "  for i in range(num_steps):\n",
    "    adv_image = fgsm(adv_image, input_label, alpha, model_type)\n",
    "    perturbation = adv_image - input_image\n",
    "    perturbation = tf.clip_by_value(perturbation, -eps, eps)\n",
    "    adv_image = input_image + perturbation\n",
    "  \n",
    "  return adv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aarush\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 8ms/step - loss: 3.6018 - sparse_categorical_crossentropy: 2.8952 - sparse_categorical_accuracy: 0.5767 - scaled_adversarial_loss: 0.7065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.601750373840332, 2.8952455520629883, 0.57669997215271, 0.706505537033081]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgsm_x = fgsm(tf.convert_to_tensor(X_test), Y_test)\n",
    "adv_model.evaluate({'feature': fgsm_x, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 39.9592 - sparse_categorical_crossentropy: 33.1245 - sparse_categorical_accuracy: 0.0072 - scaled_adversarial_loss: 6.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[39.95924758911133, 33.12449645996094, 0.007199999876320362, 6.834768295288086]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgd_x = pgd(tf.convert_to_tensor(X_test), Y_test)\n",
    "adv_model.evaluate({'feature': pgd_x, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5363 - sparse_categorical_crossentropy: 0.4189 - sparse_categorical_accuracy: 0.9083 - scaled_adversarial_loss: 0.1174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5362680554389954,\n",
       " 0.41891056299209595,\n",
       " 0.90829998254776,\n",
       " 0.11735693365335464]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgsm_x_base = fgsm(tf.convert_to_tensor(X_test), Y_test, model_type = \"model\")\n",
    "adv_model.evaluate({'feature': fgsm_x_base, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0536 - sparse_categorical_crossentropy: 0.8238 - sparse_categorical_accuracy: 0.8399 - scaled_adversarial_loss: 0.2298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0536247491836548, 0.82384192943573, 0.839900016784668, 0.22978337109088898]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgd_x_base = pgd(tf.convert_to_tensor(X_test), Y_test, model_type = \"model\")\n",
    "adv_model.evaluate({'feature': pgd_x_base, 'label': Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] set data_format = 'channels_last'\n",
      "setting parameters for standard version\n"
     ]
    }
   ],
   "source": [
    "model_adapted = utils_tf2.ModelAdapter(model)\n",
    "adversary = AutoAttack(model_adapted, norm='Linf', eps= 0.15, version='standard', is_tf_model=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, axis = 3)\n",
    "torch_testX = torch.from_numpy(np.transpose((X_test), (0,3,1,2))).float().cuda()\n",
    "torch_testY = torch.from_numpy( Y_test ).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
      "Warning: it seems that the output is a probability distribution, please be sure that the logits are used! See flags_doc.md for details.\n",
      "Warning: the check for dynamic defenses is not currently supported\n",
      "initial accuracy: 98.77%\n",
      "apgd-ce - 1/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 2/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 3/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 4/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 5/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 6/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 7/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 8/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 9/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 10/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 11/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 12/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 13/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 14/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 15/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 16/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 17/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 18/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 19/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 20/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 21/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 22/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 23/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 24/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 25/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 26/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 27/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 28/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 29/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 30/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 31/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 32/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 33/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 34/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 35/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 36/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 37/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 38/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 39/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 40/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 41/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 42/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 43/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 44/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 45/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 46/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 47/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 48/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 49/50 - 200 out of 200 successfully perturbed\n",
      "apgd-ce - 50/50 - 77 out of 77 successfully perturbed\n",
      "robust accuracy after APGD-CE: 0.00% (total time 46.4 s)\n",
      "max Linf perturbation: 0.25000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "x_adv = adversary.run_standard_evaluation(torch_testX, torch_testY, bs = 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
